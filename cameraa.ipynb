{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OzgurCoskunn/tezz/blob/main/cameraa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07181daa",
      "metadata": {
        "id": "07181daa",
        "outputId": "cd26e21a-42a1-4bc2-b983-485288fc2306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['saglikli', 'hastalikli']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import multiprocessing\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow.keras as tf\n",
        "import math\n",
        "import os\n",
        "\n",
        "#etiketleri labels.txt dosyasından alma\n",
        "labels_path = \"C:/Users/ozgur/OneDrive/Masaüstü/dataset/MyMODEL/labels.txt\"\n",
        "labelsfile = open(labels_path, 'r')\n",
        "\n",
        "# initialize classes and read in lines until there are no more\n",
        "classes = []\n",
        "line = labelsfile.readline()\n",
        "while line:\n",
        "        # retrieve just class name and append to classes\n",
        "        classes.append(line.split(' ', 1)[1].rstrip())\n",
        "        line = labelsfile.readline()\n",
        "# close label file\n",
        "labelsfile.close()\n",
        "print(classes)\n",
        "\n",
        "# load the teachable machine model\n",
        "model_path = \"C:/Users/ozgur/OneDrive/Masaüstü/dataset/MyMODEL/finduk_detector.h5\"\n",
        "model = tf.models.load_model(model_path, compile=False)\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# width & height of webcam video in pixels -> adjust to your size\n",
        "# adjust values if you see black bars on the sides of capture window\n",
        "frameWidth = 1280\n",
        "frameHeight = 720\n",
        "\n",
        "# set width and height in pixels\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frameWidth)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frameHeight)\n",
        "# enable auto gain\n",
        "cap.set(cv2.CAP_PROP_GAIN, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7214bd",
      "metadata": {
        "id": "ee7214bd"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "\n",
        "        # disable scientific notation for clarity\n",
        "        np.set_printoptions(suppress=True)\n",
        "\n",
        "        # Create the array of the right shape to feed into the keras model.\n",
        "        # We are inputting 1x 224x224 pixel RGB image.\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "\n",
        "        # capture image\n",
        "        check, frame = cap.read()\n",
        "        frame = cv2.flip(frame, 1)  ### flip komutu ile sağ ve sol yöndeki tersliği düzelt\n",
        "\n",
        "        # crop to square for use with TM model\n",
        "        margin = int(((frameWidth-frameHeight)/2))\n",
        "        square_frame = frame[0:frameHeight, margin:margin + frameHeight]\n",
        "        # resize to 224x224 for use with TM model\n",
        "        resized_img = cv2.resize(square_frame, (224, 224))\n",
        "        # convert image color to go to model\n",
        "        model_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # turn the image into a numpy array\n",
        "        image_array = np.asarray(model_img)\n",
        "        # normalize the image\n",
        "        normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "        # load the image into the array\n",
        "        data[0] = normalized_image_array\n",
        "\n",
        "        # run the prediction\n",
        "        predictions = model.predict(data)\n",
        "\n",
        "        # confidence threshold is 90%.\n",
        "        conf_threshold = 50\n",
        "        confidence = []\n",
        "        conf_label = \"\"\n",
        "        threshold_class = \"\"\n",
        "        # create blach border at bottom for labels\n",
        "        per_line = 2  # number of classes per line of text\n",
        "        bordered_frame = cv2.copyMakeBorder(\n",
        "            square_frame,\n",
        "            top=0,\n",
        "            bottom=30 + 15*math.ceil(len(classes)/per_line),\n",
        "            left=0,\n",
        "            right=0,\n",
        "            borderType=cv2.BORDER_CONSTANT,\n",
        "            value=[0, 0, 0]\n",
        "        )\n",
        "        # for each one of the classes\n",
        "        for i in range(0, len(classes)):\n",
        "            # scale prediction confidence to % and apppend to 1-D list\n",
        "            confidence.append(int(predictions[0][i]*100))\n",
        "            # put text per line based on number of classes per line\n",
        "            if (i != 0 and not i % per_line):\n",
        "                cv2.putText(\n",
        "                    img=bordered_frame,\n",
        "                    text=conf_label,\n",
        "                    org=(int(0), int(frameHeight+25+15*math.ceil(i/per_line))),\n",
        "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    fontScale=0.5,\n",
        "                    color=(255, 255, 255)\n",
        "                )\n",
        "                conf_label = \"\"\n",
        "            # append classes and confidences to text for label\n",
        "            conf_label += classes[i] + \": \" + str(confidence[i]) + \"%; \"\n",
        "            # prints last line\n",
        "            if (i == (len(classes)-1)):\n",
        "                cv2.putText(\n",
        "                    img=bordered_frame,\n",
        "                    text=conf_label,\n",
        "                    org=(int(0), int(frameHeight+25+15*math.ceil((i+1)/per_line))),\n",
        "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    fontScale=0.5,\n",
        "                    color=(255, 255, 255)\n",
        "                )\n",
        "                conf_label = \"\"\n",
        "            # if above confidence threshold, send to queue\n",
        "            if confidence[i] > conf_threshold:\n",
        "                #speakQ.put(classes[i])\n",
        "                threshold_class = classes[i]\n",
        "        # add label class above confidence threshold\n",
        "        cv2.putText(\n",
        "            img=bordered_frame,\n",
        "            text=threshold_class,\n",
        "            org=(int(0), int(frameHeight+20)),\n",
        "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            fontScale=0.9,\n",
        "            color=(255, 255, 255)\n",
        "        )\n",
        "\n",
        "\n",
        "        # display and wait 1ms\n",
        "        cv2.imshow('webcam goruntusu', bordered_frame)\n",
        "        cv2.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7720df2a",
      "metadata": {
        "id": "7720df2a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "cameraa.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}